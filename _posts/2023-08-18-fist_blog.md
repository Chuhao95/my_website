# How to build a minimal deep learning web app from Fastai, Hugging Face Sapce, Github Page and Google Colab. A step-by-step guide for beginner

I build a minimal deep learning web app to predict which thumbnail (Youtube video's cover photo) is above or below the average click-through rate (CTR). All tools used are free! 

![thumbnail click-through rate predictor](/images/ctr.png "Youtube CTR Predictor")

You can try this app at [oldfatboy.com](https://oldfatboy.com). But it only works for my wife's [youtube channel](https://www.youtube.com/channel/UCN_hbfsIsYgj-PtGJT8aSAQ),because the model is trained based on her channel's dataset. As title mentioned, it is a MVP (Minimal Viable Product).

All steps are from the first two [lectures](https://course.fast.ai/Lessons/lesson1.html) of fast.ai's practical deep learning for coders. 

I highly recommend this practical course because it has top-down mindeset instead of traditional education's down-top mindset. In other word, it teaches you the *Whole Game* instead of making you learn details for years before even trying play the whole game.

# Table of Contents
1. [Step One: Prepare Data](#Step One: Prepare Data)
2. [Step Two: Train Model using Google Colab and Fast.ai](#Step Two: Train Model using Google Colab and Fast.ai)

1. Train deep learning model using Google Colab and Fast.ai
2. Host model to Hugging Face Space
3. Embed model to a website build from Github Page

## Step One: Prepare Data

Use Youtube API to extract thumbnail data from my wife's [Youtube Channel](https://www.youtube.com/channel/UCN_hbfsIsYgj-PtGJT8aSAQ). You need to replace `Your Youtube API` with your won API key which can be obtained from Youtube Data API key from [here](https://developers.google.com/youtube/v3).


```python
from googleapiclient.discovery import build
import pandas as pd
```


```python
# Set up API client
api_key = "AIzaSyDRtin-ZzXXEK_BUzID4se9Esk8SxrtaHk"
youtube = build('youtube', 'v3', developerKey=api_key)
```


```python
# Retrieve video data
channel_id = "UCN_hbfsIsYgj-PtGJT8aSAQ"
videos = []
next_page_token = None
```


```python
request = youtube.search().list(
            part='snippet',
            channelId=channel_id,
            maxResults=50,  # Adjust the number of results per page as needed
            pageToken=next_page_token
        )
response = request.execute()
```


```python
for item in response['items']:
  video = {}
  video['title'] = item['snippet']['title']
  video['thumbnail'] = item['snippet']['thumbnails']['default']['url']
  videos.append(video)
```


```python
# Create a Pandas DataFrame from data
df = pd.DataFrame(videos)
df.head()
```

Download csv file of click-through rate from youtube studio (Youtube studio -> Analytics -> Advanced mode -> Export current view -> Comma-seperated values (.csv)), because the Youtube API I used only allow access to public information. You can use another API to get access to creator's data but this is a minimal product.

![Download CTR data from Youtube Studio](/images/youtube_analytic.png "Download CTR data from Youtube Studio")

And upload the `Table data.csv` to the colab by drag and drop it in the left *Files* sections of colab.


```python
# Read the CSV file into a Pandas DataFrame
df_ctr = pd.read_csv('Table data.csv')
df_ctr.head()
```


```python
# Rename the df 'title' column to the same name of df_ctr whihch is 'Video title' for merging purpose
df = df.rename(columns={'title': 'Video title'})
```


```python
# Merge the DataFrames based on the video title
df_merged = pd.merge(df, df_ctr[['Video title', 'Impressions click-through rate (%)']], on='Video title', how='left')
df_merged.head()
```


```python
# Remove rows with NaN values
df_cleaned = df_merged.dropna()
df_cleaned.head()
```






<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Video title</th>
      <th>thumbnail</th>
      <th>Impressions click-through rate (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>When you want to crochet and you have a baby</td>
      <td>https://i.ytimg.com/vi/9ePFI7814Rc/default.jpg</td>
      <td>1.26</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Crochet Leaves</td>
      <td>https://i.ytimg.com/vi/jx2ojGTX854/default.jpg</td>
      <td>4.57</td>
    </tr>
    <tr>
      <th>4</th>
      <td>How to crochet pet collar | crochet tulips | B...</td>
      <td>https://i.ytimg.com/vi/M5pbgRzZs6w/default.jpg</td>
      <td>4.39</td>
    </tr>
    <tr>
      <th>5</th>
      <td>How to wrap flowers | crochet flower bouquet</td>
      <td>https://i.ytimg.com/vi/rBFqpv-m6gc/default.jpg</td>
      <td>4.69</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Crochet for beginners: How to crochet scrunchi...</td>
      <td>https://i.ytimg.com/vi/2hPsxSXwsf8/default.jpg</td>
      <td>3.11</td>
    </tr>
  </tbody>
</table>






```python
# Export merged dataframe to csv file
df_merged.to_csv('thumbnail_ctr.csv', index=False)
```

You can find the exported file in the files section of the Colab as thumbnail_ctr.csv , and you can right-click on it (or click on the three dots next to it) and then download it for model training in next step.

For blogging reason, I converted this notebook to markdown with nbconvert. Therefore, markdown file can be rendered in my personal [website](chuhaoliu.com) hosted by Github Page.

You can need to download this notebook and upload it to the folder sections in colab for the below code to run. Details shows [here](https://www.python-engineer.com/posts/convert-colab-markdown/). For some reason, nbconvert converts output of pandas dataframe (e.g. pd.head()) with html scripts. So I deleted the previous pd.head() output and only shows the last one by mannually deleted unwanted html script shown in converted markdown file.


```python
!jupyter nbconvert --to markdown Prepare_Data.ipynb
```
For deep learning training, you need to first **change the Colab runtime** to `T4 GPU` in the upper right corner.

![Change Colab Runtime to T4 GPU](/images/Change_Colab_Runtime.png "Change Colab Runtime to T4 GPU")

Upload `thumbnail_ctr.csv` to Colab by drag and drop into the left *Files* section.


## Step Two: Train Model using Google Colab and Fast.ai

```python
import pandas as pd

# Read the CSV file into a Pandas DataFrame
df = pd.read_csv('thumbnail_ctr.csv')

# Delete NaN rows
df = df.dropna()
# Reindex the DataFrame
df = df.reset_index(drop=True)
df.head()
```






<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Video title</th>
      <th>thumbnail</th>
      <th>Impressions click-through rate (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>When you want to crochet and you have a baby</td>
      <td>https://i.ytimg.com/vi/9ePFI7814Rc/default.jpg</td>
      <td>1.26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Crochet Leaves</td>
      <td>https://i.ytimg.com/vi/jx2ojGTX854/default.jpg</td>
      <td>4.57</td>
    </tr>
    <tr>
      <th>2</th>
      <td>How to crochet pet collar | crochet tulips | B...</td>
      <td>https://i.ytimg.com/vi/M5pbgRzZs6w/default.jpg</td>
      <td>4.39</td>
    </tr>
    <tr>
      <th>3</th>
      <td>How to wrap flowers | crochet flower bouquet</td>
      <td>https://i.ytimg.com/vi/rBFqpv-m6gc/default.jpg</td>
      <td>4.69</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Crochet for beginners: How to crochet scrunchi...</td>
      <td>https://i.ytimg.com/vi/2hPsxSXwsf8/default.jpg</td>
      <td>3.11</td>
    </tr>
  </tbody>
</table>





Blow is a code example of using fast.ai library to download and show images from url.


```python
from fastdownload import download_url
dest = 'thumbnail.jpg'
download_url(df['thumbnail'][2], dest, show_progress=False)

from fastai.vision.all import *
im = Image.open(dest)
im.to_thumb(256,256)
```




    
![png](/images/Download_example.png)
    




```python
average_value = df['Impressions click-through rate (%)'].mean()
average_value
```




    2.716734693877551



Seperate datasest into two caterogies: **below average** and **above average**.


```python
below_average_df = df[df['Impressions click-through rate (%)'] < average_value]
above_average_df = df[df['Impressions click-through rate (%)'] >= average_value]
```

Dowload images from two categories into two different folders named **above_average** and **below_average**. Fast.ai library will use folder's name to lable the images for training.


```python
searches = 'below_average','above_average'
path = Path('thumbnail_cover_image')

for o in searches:
    dest = (path/o)
    dest.mkdir(exist_ok=True, parents=True)
    if o == 'below average':
      o_df = below_average_df
    else:
      o_df = above_average_df

    download_images(dest, urls=o_df['thumbnail'])
    resize_images(path/o, max_size=400, dest=path/o)
```


```python
#Delete unvalid image links
failed = verify_images(get_image_files(path))
failed.map(Path.unlink)
len(failed)
```




    0




```python
#Build fast.ai datablock for next step
dls = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_items=get_image_files,
    splitter=RandomSplitter(valid_pct=0.2, seed=42),
    get_y=parent_label,
    item_tfms=[Resize(192, method='squish')]
).dataloaders(path, bs=32)

dls.show_batch(max_n=6)
```


    
![show batch](/images/show_batch.png)
    


**Fine tune** the existing **Resnet** model which has been pre-trained on millions of images. **Fine tune** method only train the last layer of the pre-trained model for the user's dataset. Therefore, it saves time.


```python
learn = vision_learner(dls, resnet18, metrics=error_rate)
learn.fine_tune(3)
```

    /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
      warnings.warn(
    /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
      warnings.warn(msg)
    Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
    100%|██████████| 44.7M/44.7M [00:00<00:00, 213MB/s]









<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.438015</td>
      <td>1.381293</td>
      <td>0.500000</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>









<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.690220</td>
      <td>1.451846</td>
      <td>0.500000</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.592969</td>
      <td>1.636217</td>
      <td>0.500000</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.496134</td>
      <td>1.836272</td>
      <td>0.600000</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>


Upload an example.jpg to text model


```python
is_above_average,_,probs = learn.predict(PILImage.create('example.jpg'))
print(f"This is a: {is_above_average}.")
print(f"Probability its click-through rate above average: {probs[0]:.4f}")
```











    This is a: above_average.
    Probability its click-through rate above average: 0.8472


Export the fine-tuned model and download from the **Files** section of colab for next step.


```python
learn.export('model.pkl')
```

Download and upload this notebook to Colab. Convert it to markdown using nbconvert for blogging reason.


```python
!jupyter nbconvert --to markdown Train_Model.ipynb
```
